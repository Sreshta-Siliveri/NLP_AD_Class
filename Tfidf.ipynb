{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as numpy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer=TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[\n",
    "    'This is the first document.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third document.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and' 'document' 'first' 'is' 'second' 'the' 'third' 'this']\n",
      "[[0.         0.38161415 0.64612892 0.38161415 0.         0.38161415\n",
      "  0.         0.38161415]\n",
      " [0.         0.63671194 0.         0.31835597 0.53902351 0.31835597\n",
      "  0.         0.31835597]\n",
      " [0.54270061 0.32052772 0.         0.32052772 0.         0.32052772\n",
      "  0.54270061 0.32052772]]\n"
     ]
    }
   ],
   "source": [
    "x=vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(x.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    10  100   11   12   15  1st   20  2day   30  4th  ...  yet   yo       you  \\\n",
      "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  ...  0.0  0.0  0.000000   \n",
      "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  ...  0.0  0.0  0.231528   \n",
      "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  ...  0.0  0.0  0.000000   \n",
      "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  ...  0.0  0.0  0.000000   \n",
      "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  ...  0.0  0.0  0.000000   \n",
      "\n",
      "   your  yours  yourself  youtube  yum  yummy   ½m  \n",
      "0   0.0    0.0       0.0      0.0  0.0    0.0  0.0  \n",
      "1   0.0    0.0       0.0      0.0  0.0    0.0  0.0  \n",
      "2   0.0    0.0       0.0      0.0  0.0    0.0  0.0  \n",
      "3   0.0    0.0       0.0      0.0  0.0    0.0  0.0  \n",
      "4   0.0    0.0       0.0      0.0  0.0    0.0  0.0  \n",
      "\n",
      "[5 rows x 1000 columns]\n"
     ]
    }
   ],
   "source": [
    "df[\"text\"]=df[\"text\"].fillna(\"\")\n",
    "vectorizer=TfidfVectorizer(max_features=1000)\n",
    "vectorizer.fit(df['text'])\n",
    "tf_idf_data_frame=pd.DataFrame(vectorizer.transform(df['text']).toarray(),columns=vectorizer.get_feature_names_out())\n",
    "print(tf_idf_data_frame.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Using cached gensim-4.3.3.tar.gz (23.3 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: pandas in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.9.1)\n",
      "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
      "  Using cached numpy-1.26.4.tar.gz (15.8 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): still running...\n",
      "  Preparing metadata (pyproject.toml): still running...\n",
      "  Preparing metadata (pyproject.toml): still running...\n",
      "  Preparing metadata (pyproject.toml): still running...\n",
      "  Preparing metadata (pyproject.toml): still running...\n",
      "  Preparing metadata (pyproject.toml): still running...\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
      "  Using cached scipy-1.13.1.tar.gz (57.2 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Preparing metadata (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [47 lines of output]\n",
      "      + meson setup C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-install-u4jgdrk0\\scipy_4bb77a47bbbe469a9470ab14635a79a5 C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-install-u4jgdrk0\\scipy_4bb77a47bbbe469a9470ab14635a79a5\\.mesonpy-mdog5r4f -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-install-u4jgdrk0\\scipy_4bb77a47bbbe469a9470ab14635a79a5\\.mesonpy-mdog5r4f\\meson-python-native-file.ini\n",
      "      The Meson build system\n",
      "      Version: 1.7.0\n",
      "      Source dir: C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-install-u4jgdrk0\\scipy_4bb77a47bbbe469a9470ab14635a79a5\n",
      "      Build dir: C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-install-u4jgdrk0\\scipy_4bb77a47bbbe469a9470ab14635a79a5\\.mesonpy-mdog5r4f\n",
      "      Build type: native build\n",
      "      Project name: scipy\n",
      "      Project version: 1.13.1\n",
      "      Activating VS 17.12.4\n",
      "      C compiler for the host machine: cl (msvc 19.42.34436 \"Microsoft (R) C/C++ Optimizing Compiler Version 19.42.34436 for x64\")\n",
      "      C linker for the host machine: link link 14.42.34436.0\n",
      "      C++ compiler for the host machine: cl (msvc 19.42.34436 \"Microsoft (R) C/C++ Optimizing Compiler Version 19.42.34436 for x64\")\n",
      "      C++ linker for the host machine: link link 14.42.34436.0\n",
      "      Cython compiler for the host machine: cython (cython 3.0.11)\n",
      "      Host machine cpu family: x86_64\n",
      "      Host machine cpu: x86_64\n",
      "      Program python found: YES (C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\python.exe)\n",
      "      Run-time dependency python found: YES 3.13\n",
      "      Program cython found: YES (C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-build-env-09he85wi\\overlay\\Scripts\\cython.EXE)\n",
      "      Compiler for C supports arguments -Wno-unused-but-set-variable: NO\n",
      "      Compiler for C supports arguments -Wno-unused-function: NO\n",
      "      Compiler for C supports arguments -Wno-conversion: NO\n",
      "      Compiler for C supports arguments -Wno-misleading-indentation: NO\n",
      "      Library m found: NO\n",
      "      \n",
      "      ..\\meson.build:78:0: ERROR: Unknown compiler(s): [['ifort'], ['gfortran'], ['flang-new'], ['flang'], ['pgfortran'], ['g95']]\n",
      "      The following exception(s) were encountered:\n",
      "      Running `ifort --help` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `ifort --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `ifort -V` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `gfortran --help` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `gfortran --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `gfortran -V` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `flang-new --help` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `flang-new --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `flang-new -V` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `flang --help` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `flang --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `flang -V` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `pgfortran --help` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `pgfortran --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `pgfortran -V` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `g95 --help` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `g95 --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `g95 -V` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      \n",
      "      A full log can be found at C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-install-u4jgdrk0\\scipy_4bb77a47bbbe469a9470ab14635a79a5\\.mesonpy-mdog5r4f\\meson-logs\\meson-log.txt\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim pandas nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[\n",
    "    \"I'd like an apple\",\n",
    "    \"An apple a day keeps the doctor away\",\n",
    "    \"Never compare an apple to orange\",\n",
    "    \"I prefer scikit-learn to orange\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_corpus=[word_tokenize(sentence) for sentence in corpus]\n",
    "print(tokenize_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=word2vec.Word2Vec(tokenize_corpus, vector_size=100, windows=5, min_count=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "review1=\"Yesterday movie is very fantastic ,it is great to see the latest version of the latest release.\"\n",
    "review2=\"The latest release is available at ibomma website ,it will be released soon.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    tokenize=word_tokenize(text)\n",
    "    tokenize=[word.lower() for word in tokenize]\n",
    "    stop_words=set(stopwords.words(\"english\"))\n",
    "    tokenize=[word for word in tokenize if word not in stop_words]\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    tokenize=[lemmatizer.lemmatize(word) for word in tokenize]\n",
    "    return \" \".join(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yesterday movie fantastic , great see latest version latest release .\n",
      "latest release available ibomma website , released soon .\n"
     ]
    }
   ],
   "source": [
    "a=preprocess_text(review1)\n",
    "b=preprocess_text(review2)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.342369   0.342369   0.         0.48719673 0.342369\n",
      "  0.24359836 0.         0.342369   0.         0.342369   0.\n",
      "  0.342369  ]\n",
      " [0.4078241  0.         0.         0.4078241  0.29017021 0.\n",
      "  0.29017021 0.4078241  0.         0.4078241  0.         0.4078241\n",
      "  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer=TfidfVectorizer()\n",
    "vectors=vectorizer.fit_transform([a,b])\n",
    "print(vectors.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.212\n"
     ]
    }
   ],
   "source": [
    "cosin_sim=cosine_similarity(vectors[0],vectors[1])[0][0]\n",
    "print(round(cosin_sim,3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
